{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"4v3T2J7t9eEv"},"outputs":[],"source":["# Советы по использованию блокнотов в Google Colab см.\n","# https://pytorch.org/tutorials/beginner/colab\n","%matplotlib inline"]},{"cell_type":"markdown","metadata":{"id":"_YIX1O5c9eEy"},"source":["Создание чат-бот в рамках обучения\n","================\n","\n","**Author:** [Matthew Inkawhich](https://github.com/MatthewInkawhich)\n"]},{"cell_type":"markdown","metadata":{"id":"qmKQTMO09eE0"},"source":["В этом уроке мы рассмотрим забавный и интересный пример использования моделей повторяющейся последовательности-в-последовательность. Мы обучим простого чат-бота, используя сценарии фильмов из [Cornell Movie-Dialogs\n","Corpus](https://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html).\n","\n","Разговорные модели являются горячей темой в исследованиях искусственного интеллекта. Чат-боты могут быть найдены в различных условиях, включая приложения обслуживания клиентов и онлайн-службы поддержки. Эти боты часто работают на основе моделей на основе поиска, которые выдают предопределенные ответы на вопросы определенных форм. В строго ограниченной области, такой как служба поддержки ИТ компании, этих моделей может быть достаточно, однако они недостаточно надежны для более общих случаев использования. Обучение машины вести осмысленный разговор с человеком в нескольких областях — это исследовательский вопрос, который далек от решения. В последнее время бум глубокого обучения позволил создать мощные генеративные модели, такие как Google [Neural\n","Conversational Model](https://arxiv.org/abs/1506.05869), что знаменует собой большой шаг к многодоменным генеративным разговорным моделям. В этом руководстве мы реализуем этот тип модели в PyTorch.\n","\n","![](https://pytorch.org/tutorials/_static/img/chatbot/bot.png)\n","\n","``` {.sourceCode .python}\n","> hello?\n","Bot: hello .\n","> where am I?\n","Bot: you re in a hospital .\n","> who are you?\n","Bot: i m a lawyer .\n","> how are you doing?\n","Bot: i m fine .\n","> are you my friend?\n","Bot: no .\n","> you're under arrest\n","Bot: i m trying to help you !\n","> i'm just kidding\n","Bot: i m sorry .\n","> where are you from?\n","Bot: san francisco .\n","> it's time for me to leave\n","Bot: i know .\n","> goodbye\n","Bot: goodbye .\n","```\n","\n","**Основные моменты урока**\n","\n","-   Управление загрузкой и предварительной обработкой набора данных [Cornell Movie-Dialogs\n","    Corpus](https://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html)\n","    dataset\n","-   Реализовать модель «последовательность-последовательность» с [Luong attention\n","    mechanism(s)](https://arxiv.org/abs/1508.04025)\n","-   Совместное обучение моделей кодера и декодера с использованием мини-пакетов\n","-   Реализовать модуль декодирования жадного поиска\n","-   Взаимодействуйте с обученным чат-ботом\n"]},{"cell_type":"markdown","metadata":{"id":"Bw_BS2sI9eE1"},"source":["Подготовка\n","============\n","\n","Для начала загрузите ZIP-файл данных\n","[здесь](https://zissou.infosci.cornell.edu/convokit/datasets/movie-corpus/movie-corpus.zip)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fUYRgAsZ9eE1"},"outputs":[],"source":["# and put in a ``data/`` directory under the current directory.\n","#\n","# After that, let’s import some necessities.\n","#\n","\n","import torch\n","from torch.jit import script, trace\n","import torch.nn as nn\n","from torch import optim\n","import torch.nn.functional as F\n","import csv\n","import random\n","import re\n","import os\n","import unicodedata\n","import codecs\n","from io import open\n","import itertools\n","import math\n","import json\n","\n","\n","USE_CUDA = torch.cuda.is_available()\n","device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")"]},{"cell_type":"markdown","metadata":{"id":"2YbX1gkk9eE2"},"source":["Загрузка и предварительная обработка данных\n","======================\n","\n","Следующим шагом будет переформатирование нашего файла данных и загрузка данных в структуры, с которыми мы сможем работать.\n","\n","[Cornell Movie-Dialogs\n","Corpus](https://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html)\n","представляет собой богатый набор данных диалогов персонажей фильмов:\n","\n","-   220 579 диалогов между 10 292 парами персонажей фильмов\n","-   9035 персонажей из 617 фильмов\n","-   304 713 всего высказываний\n","\n","Этот набор данных большой и разнообразный, и в нем наблюдается большое разнообразие языковых формальностей, временных периодов, настроений и т. д. Мы надеемся, что это разнообразие сделает нашу модель устойчивой ко многим формам входных данных и запросов.\n","\n","Сначала мы рассмотрим некоторые строки нашего файла данных, чтобы увидеть исходный формат.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qdQVrWO59eE2"},"outputs":[],"source":["corpus_name = \"movie-corpus\"\n","corpus = os.path.join(\"data\", corpus_name)\n","\n","def printLines(file, n=10):\n","    with open(file, 'rb') as datafile:\n","        lines = datafile.readlines()\n","    for line in lines[:n]:\n","        print(line)\n","\n","printLines(os.path.join(corpus, \"utterances.jsonl\"))"]},{"cell_type":"markdown","metadata":{"id":"bhiSQd1Z9eE3"},"source":["Создать форматированный файл данных\n","==========================\n","\n","Для удобства мы создадим красиво отформатированный файл данных, в котором каждая строка будет содержать *предложение запроса* , разделенное табуляцией , и пару *предложений ответа*.\n","\n","Следующие функции облегчают анализ файла необработанных данных `utterances.jsonl`.\n","\n","-   `loadLinesAndConversations` разбивает каждую строку файла на словарь строк с полями: `lineID`, `characterID`и текст, а затем группирует их в диалоги с полями: `conversationID`, `movieID`, и строки.\n","-   `extractSentencePairs` извлекает пары предложений из разговоров\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OBCKv4ie9eE3"},"outputs":[],"source":["# Разбивает каждую строку файла для создания строк и разговоров\n","def loadLinesAndConversations(fileName):\n","    lines = {}\n","    conversations = {}\n","    with open(fileName, 'r', encoding='iso-8859-1') as f:\n","        for line in f:\n","            lineJson = json.loads(line)\n","            # Извлечение полей для линейного объекта\n","            lineObj = {}\n","            lineObj[\"lineID\"] = lineJson[\"id\"]\n","            lineObj[\"characterID\"] = lineJson[\"speaker\"]\n","            lineObj[\"text\"] = lineJson[\"text\"]\n","            lines[lineObj['lineID']] = lineObj\n","\n","            # Извлечь поля для объекта разговора\n","            if lineJson[\"conversation_id\"] not in conversations:\n","                convObj = {}\n","                convObj[\"conversationID\"] = lineJson[\"conversation_id\"]\n","                convObj[\"movieID\"] = lineJson[\"meta\"][\"movie_id\"]\n","                convObj[\"lines\"] = [lineObj]\n","            else:\n","                convObj = conversations[lineJson[\"conversation_id\"]]\n","                convObj[\"lines\"].insert(0, lineObj)\n","            conversations[convObj[\"conversationID\"]] = convObj\n","\n","    return lines, conversations\n","\n","\n","# Извлекает пары предложений из разговоров\n","def extractSentencePairs(conversations):\n","    qa_pairs = []\n","    for conversation in conversations.values():\n","        # Перебрать все строки разговора\n","        for i in range(len(conversation[\"lines\"]) - 1):  # Игнорируем последнюю строку (на нее нет ответа)\n","            inputLine = conversation[\"lines\"][i][\"text\"].strip()\n","            targetLine = conversation[\"lines\"][i+1][\"text\"].strip()\n","            # Отфильтровать неправильные образцы (если один из списков пуст)\n","            if inputLine and targetLine:\n","                qa_pairs.append([inputLine, targetLine])\n","    return qa_pairs"]},{"cell_type":"markdown","metadata":{"id":"ahPxiOi79eE6"},"source":["Теперь мы вызовем эти функции и создадим файл. Мы назовем это `formatted_movie_lines.txt`.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vCLN-oOl9eE7"},"outputs":[],"source":["# Определить путь к новому файлу\n","datafile = os.path.join(corpus, \"formatted_movie_lines.txt\")\n","\n","delimiter = '\\t'\n","# Убрать разделитель\n","delimiter = str(codecs.decode(delimiter, \"unicode_escape\"))\n","\n","# Инициализировать dict строки и dict разговоры\n","lines = {}\n","conversations = {}\n","# Загрузка строк и разговоров\n","print(\"\\nProcessing corpus into lines and conversations...\")\n","lines, conversations = loadLinesAndConversations(os.path.join(corpus, \"utterances.jsonl\"))\n","\n","# Записать новый CSV-файл\n","print(\"\\nWriting newly formatted file...\")\n","with open(datafile, 'w', encoding='utf-8') as outputfile:\n","    writer = csv.writer(outputfile, delimiter=delimiter, lineterminator='\\n')\n","    for pair in extractSentencePairs(conversations):\n","        writer.writerow(pair)\n","\n","# Распечатать образец строк\n","print(\"\\nSample lines from file:\")\n","printLines(datafile)"]},{"cell_type":"markdown","metadata":{"id":"T5n3ruT-9eE7"},"source":["Данные по загрузке и обрезке\n","==================\n","\n","Наша следующая задача — создать словарь и загрузить пары предложений запрос/ответ в память.\n","\n","Обратите внимание, что мы имеем дело с последовательностями **слов** , которые не имеют неявного отображения на дискретное числовое пространство. Таким образом, мы должны создать его, отобразив каждое уникальное слово, которое мы встречаем в нашем наборе данных, на значение индекса.\n","\n","Для этого мы определяем `Voc` класс, который хранит отображение слов в индексы, обратное отображение индексов в слова, количество каждого слова и общее количество слов. Класс предоставляет методы для добавления слова в словарь (`addWord`), добавления всех слов в предложение (`addSentence`)\n","и обрезки редко встречающихся слов (`trim`). Подробнее об обрезке позже.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y0Ytabbm9eE7"},"outputs":[],"source":["# Токены слов по умолчанию\n","PAD_token = 0  # Используется для заполнения коротких предложений padding-short-sentences\n","SOS_token = 1  # Токен начала предложения start-of-sentences\n","EOS_token = 2  # Токен конца предложения end-of-sentences\n","\n","class Voc:\n","    def __init__(self, name):\n","        self.name = name\n","        self.trimmed = False\n","        self.word2index = {}\n","        self.word2count = {}\n","        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n","        self.num_words = 3  # Count SOS, EOS, PAD\n","\n","    def addSentence(self, sentence):\n","        for word in sentence.split(' '):\n","            self.addWord(word)\n","\n","    def addWord(self, word):\n","        if word not in self.word2index:\n","            self.word2index[word] = self.num_words\n","            self.word2count[word] = 1\n","            self.index2word[self.num_words] = word\n","            self.num_words += 1\n","        else:\n","            self.word2count[word] += 1\n","\n","    # Удалить слова ниже определенного порога подсчета\n","    def trim(self, min_count):\n","        if self.trimmed:\n","            return\n","        self.trimmed = True\n","\n","        keep_words = []\n","\n","        for k, v in self.word2count.items():\n","            if v >= min_count:\n","                keep_words.append(k)\n","\n","        print('keep_words {} / {} = {:.4f}'.format(\n","            len(keep_words), len(self.word2index), len(keep_words) / len(self.word2index)\n","        ))\n","\n","        # Повторная инициализация словарей\n","        self.word2index = {}\n","        self.word2count = {}\n","        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n","        self.num_words = 3 # Подсчет токенов по умолчанию\n","\n","        for word in keep_words:\n","            self.addWord(word)"]},{"cell_type":"markdown","metadata":{"id":"M1lYHUio9eE7"},"source":["Теперь мы можем собрать наш словарь и пары предложений «запрос/ответ». Прежде чем мы будем готовы использовать эти данные, мы должны выполнить некоторые предварительная обработка. Во-первых, мы должны преобразовать строки Unicode в ASCII, используя\n","`unicodeToAscii`. Затем мы должны преобразовать все буквы в строчные и обрезать все небуквенные символы, за исключением основных знаков препинания\n","(`normalizeString`). Наконец, чтобы помочь в обучении сходимости, мы отфильтруем предложения, длина которых больше порогового `MAX_LENGTH` значения\n","(`filterPairs`).\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Lp1bdi-k9eE8"},"outputs":[],"source":["MAX_LENGTH = 10  # Максимальная длина предложения, которую следует учитывать\n","\n","# Превратите строку Unicode в обычный ASCII благодаря\n","# https://stackoverflow.com/a/518232/2809427\n","def unicodeToAscii(s):\n","    return ''.join(\n","        c for c in unicodedata.normalize('NFD', s)\n","        if unicodedata.category(c) != 'Mn'\n","    )\n","\n","# Строчные буквы, обрезка и удаление небуквенных символов\n","def normalizeString(s):\n","    s = unicodeToAscii(s.lower().strip())\n","    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n","    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n","    s = re.sub(r\"\\s+\", r\" \", s).strip()\n","    return s\n","\n","# Прочитайте пары запрос/ответ и верните объект voc.\n","def readVocs(datafile, corpus_name):\n","    print(\"Reading lines...\")\n","    # Прочитайте файл и разбейте его на строки.\n","    lines = open(datafile, encoding='utf-8').\\\n","        read().strip().split('\\n')\n","    # Разбейте каждую строку на пары и нормализуйте\n","    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n","    voc = Voc(corpus_name)\n","    return voc, pairs\n","\n","# Возвращает значение True, если оба предложения в паре «p» находятся ниже порога MAX_LENGTH.\n","def filterPair(p):\n","    # Входные последовательности должны сохранять последнее слово для токена EOS.\n","    return len(p[0].split(' ')) < MAX_LENGTH and len(p[1].split(' ')) < MAX_LENGTH\n","\n","# Фильтруйте пары, используя условие filterPair.\n","def filterPairs(pairs):\n","    return [pair for pair in pairs if filterPair(pair)]\n","\n","# Используя определенные выше функции, верните заполненный объект voc и список пар.\n","def loadPrepareData(corpus, corpus_name, datafile, save_dir):\n","    print(\"Start preparing training data ...\")\n","    voc, pairs = readVocs(datafile, corpus_name)\n","    print(\"Read {!s} sentence pairs\".format(len(pairs)))\n","    pairs = filterPairs(pairs)\n","    print(\"Trimmed to {!s} sentence pairs\".format(len(pairs)))\n","    print(\"Counting words...\")\n","    for pair in pairs:\n","        voc.addSentence(pair[0])\n","        voc.addSentence(pair[1])\n","    print(\"Counted words:\", voc.num_words)\n","    return voc, pairs\n","\n","\n","# Загрузить/собрать voc и пары\n","save_dir = os.path.join(\"data\", \"save\")\n","voc, pairs = loadPrepareData(corpus, corpus_name, datafile, save_dir)\n","# Распечатайте несколько пар для проверки.\n","print(\"\\npairs:\")\n","for pair in pairs[:10]:\n","    print(pair)"]},{"cell_type":"markdown","metadata":{"id":"biMmyldE9eE8"},"source":["Другая тактика, которая полезна для достижения более быстрой сходимости во время обучения, — это удаление редко используемых слов из нашего словаря. Уменьшение пространства признаков также смягчит сложность функции, которую модель должна научиться аппроксимировать. Мы сделаем это в два этапа:\n","\n","1)  Обрежьте слова, используемые ниже `MIN_COUNT` порогового значения, используя  `voc.trim` функцию.\n","\n","2)  Отфильтруйте пары с сокращенными словами.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9Q9_lVBK9eE8"},"outputs":[],"source":["MIN_COUNT = 3    # Минимальный порог количества слов для обрезки\n","\n","def trimRareWords(voc, pairs, MIN_COUNT):\n","    # Обрезать слова, использованные меньше MIN_COUNT, из voc\n","    voc.trim(MIN_COUNT)\n","    # Отфильтровать пары с обрезанными словами\n","    keep_pairs = []\n","    for pair in pairs:\n","        input_sentence = pair[0]\n","        output_sentence = pair[1]\n","        keep_input = True\n","        keep_output = True\n","        # Проверить входное предложение\n","        for word in input_sentence.split(' '):\n","            if word not in voc.word2index:\n","                keep_input = False\n","                break\n","        # Проверить выходное предложение\n","        for word in output_sentence.split(' '):\n","            if word not in voc.word2index:\n","                keep_output = False\n","                break\n","\n","        # Сохраняйте только пары, которые не содержат обрезанных слов во\n","        # входном или выходном предложении.\n","        if keep_input and keep_output:\n","            keep_pairs.append(pair)\n","\n","    print(\"Trimmed from {} pairs to {}, {:.4f} of total\".format(len(pairs), len(keep_pairs), len(keep_pairs) / len(pairs)))\n","    return keep_pairs\n","\n","\n","# Обрезать voc и пары\n","pairs = trimRareWords(voc, pairs, MIN_COUNT)"]},{"cell_type":"markdown","metadata":{"id":"e-1YvB4D9eE8"},"source":["Подготовка данных для моделей\n","=======================\n","\n","Хотя мы приложили немало усилий для подготовки и преобразования наших данных в хороший словарный объект и список пар предложений, наши модели в конечном итоге будут ожидать числовые тензоры torch в качестве входных данных. Один из способов подготовки обработанных данных для моделей можно найти в руководстве по\n","[seq2seq translation\n","tutorial](https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html).\n","В этом руководстве мы используем размер пакета 1, что означает, что все, что нам нужно сделать, это преобразовать слова в наших парах предложений в соответствующие им индексы из словаря и передать это моделям.\n","\n","Однако если вы заинтересованы в ускорении обучения и/или хотите использовать возможности распараллеливания графического процессора, вам придется тренироваться с помощью мини-пакетов.\n","\n","Использование мини-пакетов также означает, что мы должны помнить об изменении длины предложений в наших пакетах. Чтобы разместить предложения разных размеров в одном пакете, мы сделаем наш пакетный входной тензор формы\n","*(max\\_length, batch\\_size)*,  где предложения короче\n","*max\\_length* будут дополнены нулями после *EOS\\_token*.\n","\n","Если мы просто преобразуем наши английские предложения в тензоры, преобразуя слова в их индексы (`indexesFromSentence`) и zero-pad, наш тензор будет иметь форму  *(batch\\_size, max\\_length)* а индексация первого измерения вернет полную последовательность по всем временным шагам. Однако нам нужно иметь возможность индексировать наш пакет по времени и по всем последовательностям в пакете. Поэтому мы транспонируем нашу входную форму пакета в\n","*(max\\_length, batch\\_size)*, так что индексация по первому измерению вернет временной шаг по всем предложениям в пакете. Мы обрабатываем эту транспозицию неявно в функции `zeroPadding`.\n","\n","![](https://pytorch.org/tutorials/_static/img/chatbot/seq2seq_batches.png){.align-center}\n","\n","Функция `inputVar` брабатывает процесс преобразования предложений в тензор, в конечном итоге создавая правильно сформированный тензор с нулевым дополнением. Она также возвращает тензор `lengths` для каждой из последовательностей в пакете, который будет передан нашему декодеру позже.\n","\n","Функция  `outputVar` выполняет функцию, похожую на `inputVar`, но вместо возврата `lengths` тензора она возвращает бинарный тензор маски и максимальную целевую длину предложения. Бинарный тензор маски имеет ту же форму, что и выходной целевой тензор, но каждый элемент, который является\n","*PAD\\_token* , равен 0, а все остальные равны 1.\n","\n","`batch2TrainData` просто берет группу пар и возвращает входные и целевые тензоры, используя вышеупомянутые функции.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-DPY-x599eE9"},"outputs":[],"source":["def indexesFromSentence(voc, sentence):\n","    return [voc.word2index[word] for word in sentence.split(' ')] + [EOS_token]\n","\n","\n","def zeroPadding(l, fillvalue=PAD_token):\n","    return list(itertools.zip_longest(*l, fillvalue=fillvalue))\n","\n","def binaryMatrix(l, value=PAD_token):\n","    m = []\n","    for i, seq in enumerate(l):\n","        m.append([])\n","        for token in seq:\n","            if token == PAD_token:\n","                m[i].append(0)\n","            else:\n","                m[i].append(1)\n","    return m\n","\n","# Возвращает дополненный тензор и длину входной последовательности\n","def inputVar(l, voc):\n","    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n","    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n","    padList = zeroPadding(indexes_batch)\n","    padVar = torch.LongTensor(padList)\n","    return padVar, lengths\n","\n","# Возвращает дополненный тензор целевой последовательности,\n","#маску заполнения и максимальную целевую длину.\n","def outputVar(l, voc):\n","    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n","    max_target_len = max([len(indexes) for indexes in indexes_batch])\n","    padList = zeroPadding(indexes_batch)\n","    mask = binaryMatrix(padList)\n","    mask = torch.BoolTensor(mask)\n","    padVar = torch.LongTensor(padList)\n","    return padVar, mask, max_target_len\n","\n","# Возвращает все элементы для заданной партии пар.\n","def batch2TrainData(voc, pair_batch):\n","    pair_batch.sort(key=lambda x: len(x[0].split(\" \")), reverse=True)\n","    input_batch, output_batch = [], []\n","    for pair in pair_batch:\n","        input_batch.append(pair[0])\n","        output_batch.append(pair[1])\n","    inp, lengths = inputVar(input_batch, voc)\n","    output, mask, max_target_len = outputVar(output_batch, voc)\n","    return inp, lengths, output, mask, max_target_len\n","\n","\n","# Пример проверки\n","small_batch_size = 5\n","batches = batch2TrainData(voc, [random.choice(pairs) for _ in range(small_batch_size)])\n","input_variable, lengths, target_variable, mask, max_target_len = batches\n","\n","print(\"input_variable:\", input_variable)\n","print(\"lengths:\", lengths)\n","print(\"target_variable:\", target_variable)\n","print(\"mask:\", mask)\n","print(\"max_target_len:\", max_target_len)"]},{"cell_type":"markdown","metadata":{"id":"WcVohsOG9eE9"},"source":["Определить модели\n","=============\n","\n","Модель Seq2Seq\n","-------------\n","\n","Мозг нашего чат-бота — это модель последовательность-в-последовательность (seq2seq). Цель модели seq2seq — взять последовательность переменной длины в качестве входных данных и вернуть последовательность переменной длины в качестве выходных данных с использованием модели фиксированного размера.\n","\n","[Sutskever et al.](https://arxiv.org/abs/1409.3215) обнаружили, что, используя две отдельные рекуррентные нейронные сети вместе, мы можем выполнить эту задачу. Одна RNN действует как **encoder**,  который кодирует входную последовательность переменной длины в вектор контекста фиксированной длины. Теоретически этот вектор контекста (последний скрытый слой RNN) будет содержать семантическую информацию о предложении запроса, которое вводится боту. Вторая RNN является **decoder** , который принимает входное слово и вектор контекста и возвращает предположение для следующего слова в последовательности и скрытое состояние для использования в следующей итерации.\n","\n","![](https://pytorch.org/tutorials/_static/img/chatbot/seq2seq_ts.png){.align-center}\n","\n","Источник изображения:\n","<https://jeddy92.github.io/JEddy92.github.io/ts_seq2seq_intro/>\n"]},{"cell_type":"markdown","metadata":{"id":"sYMYm5hW9eE9"},"source":["Encoder\n","=======\n","\n","Кодер RNN перебирает входное предложение по одному токену (например, слову) за раз, на каждом временном шаге выводя вектор «выходного» и вектор «скрытого состояния». Затем вектор скрытого состояния передается на следующий временной шаг, в то время как выходной вектор записывается. Кодер преобразует контекст, который он видел в каждой точке последовательности, в набор точек в многомерном пространстве, который декодер будет использовать для генерации осмысленного вывода для данной задачи.\n","\n","В основе нашего кодировщика лежит многослойный Gated Recurrent Unit, изобретенный [Cho et al.](https://arxiv.org/pdf/1406.1078v3.pdf) в 2014 году. Мы будем использовать двунаправленный вариант GRU, что означает, что по сути есть две независимые RNN: одна, которая получает входную последовательность в нормальном последовательном порядке, и другая, которая получает входную последовательность в обратном порядке. Выходы каждой сети суммируются на каждом временном шаге. Использование двунаправленного GRU даст нам преимущество кодирования как прошлых, так и будущих контекстов.\n","\n","Двунаправленная RNN:\n","\n","![](https://pytorch.org/tutorials/_static/img/chatbot/RNN-bidirectional.png){.align-center\n","width=\"70.0%\"}\n","\n","Источник изображения: <https://colah.github.io/posts/2015-09-NN-Types-FP/>\n","\n","Обратите внимание, что `embedding` слой используется для кодирования индексов наших слов в пространстве признаков произвольного размера. Для наших моделей этот слой будет отображать каждое слово в пространстве признаков размером *hidden\\_size*. При обучении эти значения должны кодировать семантическое сходство между словами с похожим значением.\n","\n","Наконец, при передаче дополненного пакета последовательностей в модуль RNN мы должны упаковать и распаковать заполнение вокруг прохода RNN, используя\n","`nn.utils.rnn.pack_padded_sequence` и\n","`nn.utils.rnn.pad_packed_sequence` соответственно.\n","\n","**График вычислений:**\n","\n","> 1)  Преобразовать индексы слов в embedding.\n","> 2)  Упакуйте padded batch (\"рамочный\" пакет) последовательностей для модуля RNN.\n","> 3)  Прямой проход через сеть GRU (Gated Recurrent Unit).\n","> 4)  Распакуйте padding.\n","> 5)  Просуммируйте двунаправленные выходы GRU.\n","> 6)  Возвратите выходные данные и конечное скрытое состояние.\n","\n","**Inputs:**\n","\n","-   `input_seq`: пакет входных предложений; shape=*(max\\_length,\n","    batch\\_size)*\n","-   `input_lengths`: список длин предложений, соответствующих каждому предложению в пакете;  shape=*(batch\\_size)*\n","-   `hidden`:  скрытое состояние;  shape=*(n\\_layers x num\\_directions,\n","    batch\\_size, hidden\\_size)*\n","\n","**Outputs:**\n","\n","-   `outputs`: выходные признаки из последнего скрытого слоя GRU (сумма двунаправленных выходов);\n","    (sum of bidirectional outputs); shape=*(max\\_length, batch\\_size,\n","    hidden\\_size)*\n","-   `hidden`: обновленное скрытое состояние из GRU; shape=*(n\\_layers x\n","    num\\_directions, batch\\_size, hidden\\_size)*\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TZxp9cIX9eE-"},"outputs":[],"source":["class EncoderRNN(nn.Module):\n","    def __init__(self, hidden_size, embedding, n_layers=1, dropout=0):\n","        super(EncoderRNN, self).__init__()\n","        self.n_layers = n_layers\n","        self.hidden_size = hidden_size\n","        self.embedding = embedding\n","\n","        # Инициализировать GRU; для параметров input_size и Hidden_size установлено значение «hidden_size».\n","        #   потому что наш входной размер — это embedding слова с количеством функций == скрытый_размер\n","        self.gru = nn.GRU(hidden_size, hidden_size, n_layers,\n","                          dropout=(0 if n_layers == 1 else dropout), bidirectional=True)\n","\n","    def forward(self, input_seq, input_lengths, hidden=None):\n","        # Преобразование индексов слов в embedding\n","        embedded = self.embedding(input_seq)\n","        # Упаковать padded batch последовательности для RNN module\n","        packed = nn.utils.rnn.pack_padded_sequence(embedded, input_lengths)\n","        # Прямой проход через GRU\n","        outputs, hidden = self.gru(packed, hidden)\n","        # Распаковка padding\n","        outputs, _ = nn.utils.rnn.pad_packed_sequence(outputs)\n","        # СУммирование bidirectional GRU outputs\n","        outputs = outputs[:, :, :self.hidden_size] + outputs[:, : ,self.hidden_size:]\n","        # Возвратный вывод и окончательное скрытое состояние\n","        return outputs, hidden"]},{"cell_type":"markdown","metadata":{"id":"_A6yL4Ib9eE-"},"source":["Decoder\n","=======\n","\n","Декодер RNN генерирует предложение ответа по одному токену. Он использует векторы контекста кодировщика и внутренние скрытые состояния для генерации следующего слова в последовательности. Он продолжает генерировать слова, пока не выведет *EOS\\_token*, представляющий конец предложения. Распространенная проблема с vanilla seq2seq decoder заключается в том, что если мы полагаемся исключительно на вектор контекста для кодирования смысла всей входной последовательности, то, скорее всего, у нас будет потеря информации. Это особенно актуально при работе с длинными входными последовательностями, что значительно ограничивает возможности нашего декодера.\n","\n","Чтобы бороться с этим,  [Bahdanau et al.](https://arxiv.org/abs/1409.0473)\n","создали «механизм внимания», который позволяет декодеру обращать внимание на определенные части входной последовательности, а не использовать весь фиксированный контекст на каждом этапе.\n","\n","На высоком уровне внимание вычисляется с использованием текущего скрытого состояния декодера и выходов кодера. Выходные веса внимания имеют ту же форму, что и входная последовательность, что позволяет нам умножать их на выходы кодера, давая нам взвешенную сумму, которая указывает на части выходов кодера, на которые следует обратить внимание. Рисунок [Sean\n","Robertson's](https://github.com/spro) описывает это очень хорошо:\n","\n","![](https://pytorch.org/tutorials/_static/img/chatbot/attn2.png){.align-center}\n","\n","[Luong et al.](https://arxiv.org/abs/1508.04025) улучшили наработки Бахданау и др., создав «Глобальное внимание». Ключевое отличие в том, что при «Глобальном внимании» мы учитываем все скрытые состояния кодировщика, в отличие от «Локального внимания» Бахданау и др., которое учитывает только скрытое состояние кодировщика из текущего временного шага. Другое отличие в том, что при «Глобальном внимании» мы вычисляем веса внимания или энергии, используя скрытое состояние декодера только из текущего временного шага. Расчет внимания Бахданау и др. требует знания состояния декодера из предыдущего временного шага. Кроме того, Луонг и др. предоставляют различные методы для вычисления энергий внимания между выходом кодировщика и выходом декодера, которые называются «функциями оценки»:\n","\n","![](https://pytorch.org/tutorials/_static/img/chatbot/scores.png){.align-center\n","width=\"60.0%\"}\n","\n","где $h_t$ = текущее состояние целевого декодера и $\\bar{h}_s$ = все состояния кодера.\n","\n","В целом, механизм глобального внимания можно суммировать на следующем рисунке. Обратите внимание, что мы реализуем «Уровень внимания» как отдельный,  `nn.Module` назвыаемый `Attn`. Выход этого модуля — нормализованный тензор весов softmax с формой shape *(batch\\_size, 1,\n","max\\_length)*.\n","\n","![](https://pytorch.org/tutorials/_static/img/chatbot/global_attn.png){.align-center\n","width=\"60.0%\"}\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cUaQRVX-9eE-"},"outputs":[],"source":["# Luong attention layer (Уровень внимания Луонга)\n","class Attn(nn.Module):\n","    def __init__(self, method, hidden_size):\n","        super(Attn, self).__init__()\n","        self.method = method\n","        if self.method not in ['dot', 'general', 'concat']:\n","            raise ValueError(self.method, \"is not an appropriate attention method.\")\n","        self.hidden_size = hidden_size\n","        if self.method == 'general':\n","            self.attn = nn.Linear(self.hidden_size, hidden_size)\n","        elif self.method == 'concat':\n","            self.attn = nn.Linear(self.hidden_size * 2, hidden_size)\n","            self.v = nn.Parameter(torch.FloatTensor(hidden_size))\n","\n","    def dot_score(self, hidden, encoder_output):\n","        return torch.sum(hidden * encoder_output, dim=2)\n","\n","    def general_score(self, hidden, encoder_output):\n","        energy = self.attn(encoder_output)\n","        return torch.sum(hidden * energy, dim=2)\n","\n","    def concat_score(self, hidden, encoder_output):\n","        energy = self.attn(torch.cat((hidden.expand(encoder_output.size(0), -1, -1), encoder_output), 2)).tanh()\n","        return torch.sum(self.v * energy, dim=2)\n","\n","    def forward(self, hidden, encoder_outputs):\n","        # Рассчитайте веса (энергии) внимания по данной методике.\n","        if self.method == 'general':\n","            attn_energies = self.general_score(hidden, encoder_outputs)\n","        elif self.method == 'concat':\n","            attn_energies = self.concat_score(hidden, encoder_outputs)\n","        elif self.method == 'dot':\n","            attn_energies = self.dot_score(hidden, encoder_outputs)\n","\n","        # Транспонировать размеры max_length и Batch_size\n","        attn_energies = attn_energies.t()\n","\n","        # Возвращает нормализованные оценки вероятности softmax (с добавленным измерением)\n","        return F.softmax(attn_energies, dim=1).unsqueeze(1)"]},{"cell_type":"markdown","metadata":{"id":"Q0bct2Em9eE-"},"source":["Теперь, когда мы определили наш подмодуль внимания, мы можем реализовать фактическую модель декодера. Для декодера мы будем вручную подавать нашу партию по одному временному шагу за раз. Это означает, что наш встроенный тензор слов и выход GRU будут иметь форму shape *(1, batch\\_size, hidden\\_size)*.\n","\n","**График вычислений:**\n","\n","> - 1)  Получить embedding текущего входного слова.\n","> - 2)  Проход вперед через однонаправленный unidirectional GRU.\n","> - 3)  Рассчитайте веса внимания на основе текущих выходных данных GRU из (2).\n","> - 4)  Умножьте веса внимания на выходы кодера, чтобы получить новый вектор контекста «взвешенной суммы».\n",">     \\\"weighted sum\\\" context vector.\n","> - 5)  Concatenate Объединить взвешенный вектор контекста и выходные данные GRU  используя уравнение Луонга eq. 5.\n","> - 6)  Предскажите следующее слово, используя уравнение Луонга 6 (без softmax).\n","> - 7)  Возврат выходных данных и конечного скрытого состояния.\n","\n","**Inputs:**\n","\n","-   `input_step`: один временной шаг (одно слово) пакета входной последовательности;\n","    shape=*(1, batch\\_size)*\n","-   `last_hidden`: последний скрытый слой GRU; shape=*(n\\_layers x\n","    num\\_directions, batch\\_size, hidden\\_size)*\n","-   `encoder_outputs`: выходные данные модели кодировщика; shape=*(max\\_length,\n","    batch\\_size, hidden\\_size)*\n","\n","**Outputs:**\n","\n","-   `output`: нормализованный тензор softmax, дающий вероятности того, что каждое слово является правильным следующим словом в декодированной последовательности; shape=*(batch\\_size, voc.num\\_words)*\n","-   `hidden`: конечное скрытое состояние GRU;; shape=*(n\\_layers x\n","    num\\_directions, batch\\_size, hidden\\_size)*\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CBwEE9IX9eE-"},"outputs":[],"source":["class LuongAttnDecoderRNN(nn.Module):\n","    def __init__(self, attn_model, embedding, hidden_size, output_size, n_layers=1, dropout=0.1):\n","        super(LuongAttnDecoderRNN, self).__init__()\n","\n","        # Сохранить для справки\n","        self.attn_model = attn_model\n","        self.hidden_size = hidden_size\n","        self.output_size = output_size\n","        self.n_layers = n_layers\n","        self.dropout = dropout\n","\n","        # Определение слоев\n","        self.embedding = embedding\n","        self.embedding_dropout = nn.Dropout(dropout)\n","        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=(0 if n_layers == 1 else dropout))\n","        self.concat = nn.Linear(hidden_size * 2, hidden_size)\n","        self.out = nn.Linear(hidden_size, output_size)\n","\n","        self.attn = Attn(attn_model, hidden_size)\n","\n","    def forward(self, input_step, last_hidden, encoder_outputs):\n","        # Примечание: мы выполняем этот шаг (слово) за раз.\n","        # Получить embedding текущего входного слова\n","        embedded = self.embedding(input_step)\n","        embedded = self.embedding_dropout(embedded)\n","        # Проход вперед unidirectional GRU\n","        rnn_output, hidden = self.gru(embedded, last_hidden)\n","        # Рассчитать веса внимания на основе текущих результатов GRU output\n","        attn_weights = self.attn(rnn_output, encoder_outputs)\n","        # Умножьте веса внимания на выходные данные кодера,\n","        # чтобы получить новый вектор контекста «взвешенной суммы».\n","\n","        context = attn_weights.bmm(encoder_outputs.transpose(0, 1))\n","        # Объедините вектор взвешенного контекста и\n","        # выходные данные GRU, используя уравнение Луонга. 5\n","        rnn_output = rnn_output.squeeze(0)\n","        context = context.squeeze(1)\n","        concat_input = torch.cat((rnn_output, context), 1)\n","        concat_output = torch.tanh(self.concat(concat_input))\n","        # Предскажите следующее слово, используя уравнение Луонга. 6\n","        output = self.out(concat_output)\n","        output = F.softmax(output, dim=1)\n","        # Возвратный вывод и окончательное скрытое состояние\n","        return output, hidden"]},{"cell_type":"markdown","metadata":{"id":"XPiw4Di_9eE_"},"source":["Определить процедуру обучения\n","=========================\n","\n","Скрытая потеря\n","-----------\n","\n","Поскольку мы имеем дело с пакетами дополненных последовательностей, мы не можем просто учитывать все элементы тензора при вычислении потерь. Мы определяем\n","`maskNLLLoss` вычисление наших потерь на основе выходного тензора нашего декодера, целевого тензора и бинарного тензора маски, описывающего заполнение целевого тензора. Эта функция потерь вычисляет среднее отрицательное логарифмическое правдоподобие элементов, которые соответствуют *1* в тензоре маски.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B8sR-dm59eE_"},"outputs":[],"source":["def maskNLLLoss(inp, target, mask):\n","    nTotal = mask.sum()\n","    crossEntropy = -torch.log(torch.gather(inp, 1, target.view(-1, 1)).squeeze(1))\n","    loss = crossEntropy.masked_select(mask).mean()\n","    loss = loss.to(device)\n","    return loss, nTotal.item()"]},{"cell_type":"markdown","metadata":{"id":"mwJgwKtQ9eE_"},"source":["Одна итерация обучения\n","=========================\n","\n","Функция `train` содержит алгоритм для одной итерации обучения (одной партии входных данных).\n","\n","Мы воспользуемся парой хитрых приемов, которые помогут добиться конвергенции:\n","\n","\n","\n","-   Первый трюк заключается в использовании **teacher forcing (принуждения учителя)**. Это означает, что при некоторой вероятности, установленной с помощью  `teacher_forcing_ratio`, мы используем текущее целевое слово в качестве следующего входа декодера, а не используем текущую догадку декодера. Этот метод действует как обучающие колеса для декодера, помогая в более эффективном обучении. Однако принуждение учителя может привести к нестабильности модели во время вывода, поскольку у декодера может не быть достаточного шанса по-настоящему создать свои собственные выходные последовательности во время обучения. Таким образом, мы должны помнить о том, как мы устанавливаем `teacher_forcing_ratio`, , и не обманываться быстрой сходимостью.\n","\n","-   Второй трюк, который мы реализуем, — это **gradient clipping (отсечение градиента)**. Это часто используемый метод для борьбы с проблемой «взрывного градиента». По сути, отсечением или пороговой установкой градиентов до максимального значения мы предотвращаем экспоненциальный рост градиентов и либо переполнение (NaN), либо выход за пределы крутых обрывов в функции стоимости.\n","\n","![](https://pytorch.org/tutorials/_static/img/chatbot/grad_clip.png){.align-center\n","width=\"60.0%\"}\n","\n","Источник изображения: Гудфеллоу и др. Глубокое обучение . 2016.\n","<https://www.deeplearningbook.org/>\n","\n","**Последовательность операций:**\n","\n","1.  Пропустить вперед (forward) весь входной пакет через кодер.\n","2.  Инициализируйте входы декодера как SOS\\_token, а скрытое состояние — как конечное скрытое состояние кодера.\n","3.  Передавайте входную пакетную последовательность через декодер по одному временному шагу за раз.\n","4.  Если учитель принудительно нажимает: установите следующий вход декодера в качестве текущего целевого значения; в противном случае: установите следующий вход декодера в качестве текущего выхода декодера.\n","5.  Рассчитайте и аккумулируйте убытки.\n","6.  Выполнить обратное распространение ошибки.\n","7.  Градиенты обрезки Clip gradients.\n","8.  Обновите параметры модели кодера и декодера.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w6gwQ1uh9eE_"},"outputs":[],"source":["def train(input_variable, lengths, target_variable, mask, max_target_len, encoder, decoder, embedding,\n","          encoder_optimizer, decoder_optimizer, batch_size, clip, max_length=MAX_LENGTH):\n","\n","    # Нулевые градиенты\n","    encoder_optimizer.zero_grad()\n","    decoder_optimizer.zero_grad()\n","\n","    # Установить параметры устройства\n","    input_variable = input_variable.to(device)\n","    target_variable = target_variable.to(device)\n","    mask = mask.to(device)\n","    # Длины для упаковки RNN всегда должны находиться в ЦП.\n","    lengths = lengths.to(\"cpu\")\n","\n","    # Инициализировать переменные\n","    loss = 0\n","    print_losses = []\n","    n_totals = 0\n","\n","    # Прямой проход через кодер\n","    encoder_outputs, encoder_hidden = encoder(input_variable, lengths)\n","\n","    # Создайте начальный ввод декодера (начните с токенов SOS для каждого предложения)\n","    decoder_input = torch.LongTensor([[SOS_token for _ in range(batch_size)]])\n","    decoder_input = decoder_input.to(device)\n","\n","    # Установите начальное скрытое состояние декодера\n","    # в окончательное скрытое состояние кодера.\n","    decoder_hidden = encoder_hidden[:decoder.n_layers]\n","\n","    # Определите, используем ли мы учителя, форсирующего эту итерацию.\n","    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n","\n","    # Forward batch of sequences through decoder one time step at a time\n","    # Пересылать пакет последовательностей через декодер по одному временному шагу за раз.\n","    if use_teacher_forcing:\n","        for t in range(max_target_len):\n","            decoder_output, decoder_hidden = decoder(\n","                decoder_input, decoder_hidden, encoder_outputs\n","            )\n","            # Принуждение учителя: следующий ввод — текущая цель\n","            decoder_input = target_variable[t].view(1, -1)\n","            # Посчитайте и накопите loss\n","            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n","            loss += mask_loss\n","            print_losses.append(mask_loss.item() * nTotal)\n","            n_totals += nTotal\n","    else:\n","        for t in range(max_target_len):\n","            decoder_output, decoder_hidden = decoder(\n","                decoder_input, decoder_hidden, encoder_outputs\n","            )\n","            # No teacher forcing: next input is decoder's own current output\n","            # Никакого принуждения учителя: следующим входом является собственный текущий выход декодера.\n","            _, topi = decoder_output.topk(1)\n","            decoder_input = torch.LongTensor([[topi[i][0] for i in range(batch_size)]])\n","            decoder_input = decoder_input.to(device)\n","            # Посчитайте и накопите loss\n","            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n","            loss += mask_loss\n","            print_losses.append(mask_loss.item() * nTotal)\n","            n_totals += nTotal\n","\n","    # Выполнить обратное распространение ошибки\n","    loss.backward()\n","\n","    # Clip gradients: gradients are modified in place\n","    # Градиенты клипа: градиенты изменяются на месте.\n","    _ = nn.utils.clip_grad_norm_(encoder.parameters(), clip)\n","    _ = nn.utils.clip_grad_norm_(decoder.parameters(), clip)\n","\n","    # Отрегулируйте вес модели\n","    encoder_optimizer.step()\n","    decoder_optimizer.step()\n","\n","    return sum(print_losses) / n_totals"]},{"cell_type":"markdown","metadata":{"id":"veuT6bpT9eE_"},"source":["Итерации обучения\n","===================\n","\n","Наконец, пришло время связать полную процедуру обучения с данными. Функция  `trainIters` fотвечает за запуск\n","`n_iterations` обучения с учетом переданных моделей, оптимизаторов, данных и т. д. Эта функция вполне понятна, так как мы уже проделали тяжелую работу с `train` функцией.\n","\n","Стоит отметить, что при сохранении модели мы сохраняем tarball, содержащий кодер и декодер `state_dicts` (параметры), оптимизаторы  `state_dicts`, потери, итерации и т. д Сохранение модели таким образом даст нам максимальную гибкость с контрольной точкой. После загрузки контрольной точки мы сможем использовать параметры модели для запуска вывода или продолжить обучение с того места, где остановились.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j6Y6IDPa9eE_"},"outputs":[],"source":["def trainIters(model_name, voc, pairs, encoder, decoder, encoder_optimizer, decoder_optimizer, embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size, print_every, save_every, clip, corpus_name, loadFilename):\n","\n","    # Загрузка пакетов для каждой итерации\n","    training_batches = [batch2TrainData(voc, [random.choice(pairs) for _ in range(batch_size)])\n","                      for _ in range(n_iteration)]\n","\n","    # Инициализации\n","    print('Initializing ...')\n","    start_iteration = 1\n","    print_loss = 0\n","    if loadFilename:\n","        start_iteration = checkpoint['iteration'] + 1\n","\n","    # Тренировочный цикл\n","    print(\"Training...\")\n","    for iteration in range(start_iteration, n_iteration + 1):\n","        training_batch = training_batches[iteration - 1]\n","        # Извлечь поля из пакета\n","        input_variable, lengths, target_variable, mask, max_target_len = training_batch\n","\n","        # Запуск обучающей итерации с пакетной программой\n","        loss = train(input_variable, lengths, target_variable, mask, max_target_len, encoder,\n","                     decoder, embedding, encoder_optimizer, decoder_optimizer, batch_size, clip)\n","        print_loss += loss\n","\n","        # Распечатать прогресс\n","        if iteration % print_every == 0:\n","            print_loss_avg = print_loss / print_every\n","            print(\"Iteration: {}; Percent complete: {:.1f}%; Average loss: {:.4f}\".format(iteration, iteration / n_iteration * 100, print_loss_avg))\n","            print_loss = 0\n","\n","        # Сохранить контрольную точку\n","        if (iteration % save_every == 0):\n","            directory = os.path.join(save_dir, model_name, corpus_name, '{}-{}_{}'.format(encoder_n_layers, decoder_n_layers, hidden_size))\n","            if not os.path.exists(directory):\n","                os.makedirs(directory)\n","            torch.save({\n","                'iteration': iteration,\n","                'en': encoder.state_dict(),\n","                'de': decoder.state_dict(),\n","                'en_opt': encoder_optimizer.state_dict(),\n","                'de_opt': decoder_optimizer.state_dict(),\n","                'loss': loss,\n","                'voc_dict': voc.__dict__,\n","                'embedding': embedding.state_dict()\n","            }, os.path.join(directory, '{}_{}.tar'.format(iteration, 'checkpoint')))"]},{"cell_type":"markdown","metadata":{"id":"qIZWCEU79eFA"},"source":["Определить оценку\n","=================\n","\n","После обучения модели мы хотим иметь возможность общаться с ботом самостоятельно. Во-первых, мы должны определить, как мы хотим, чтобы модель декодировала закодированный ввод.\n","\n","Жадное декодирование\n","---------------\n","\n","Жадное декодирование — это метод декодирования, который мы используем во время обучения, когда **NOT** using teacher forcing. Другими словами, для каждого временного шага мы просто выбираем слово с `decoder_output` наибольшим значением\n","softmax. Этот метод декодирования оптимален на уровне одного временного шага.\n","\n","Для облегчения операции жадного декодирования мы определяем\n","`GreedySearchDecoder` класс. При запуске объект этого класса принимает входную последовательность (`input_seq`) формы shape *(input\\_seq length, 1)*, a scalar\n","input length (`input_length`) tensor, и  `max_length` чтобы ограничить длину предложения ответа. Входное предложение оценивается с использованием следующего вычислительного графика:\n","\n","**График вычислений:**\n","\n","1.  Передача вперед входных данных через модель кодировщика.\n","2.  Подготовьте последний скрытый слой кодировщика в качестве первого скрытого входа для декодера.\n","3.  Инициализируйте первый вход декодера как SOS\\_token.\n","4.  Инициализируйте тензоры для добавления декодированных слов.\n","5.  Итеративно декодируйте по одному токену слова за раз:\n",">\n",">     :   a)  Прямой проход через декодер.\n",">         b)  олучите наиболее вероятный токен слова и его оценку softmax.\n",">         c)  Запишите token and score.\n",">         d)  Подготовьте текущий токен для следующего входа декодера.\n",">\n","6.  Возвращайте коллекции словесных токенов и оценок (word tokens and scores).\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oPNQRKPK9eFA"},"outputs":[],"source":["class GreedySearchDecoder(nn.Module):\n","    def __init__(self, encoder, decoder):\n","        super(GreedySearchDecoder, self).__init__()\n","        self.encoder = encoder\n","        self.decoder = decoder\n","\n","    def forward(self, input_seq, input_length, max_length):\n","        # Forward input through encoder model\n","        # Прямой проход ввода через модель кодировщика\n","        encoder_outputs, encoder_hidden = self.encoder(input_seq, input_length)\n","        # Подготовьте последний скрытый слой кодера, который будет первым скрытым входом в декодер.\n","        decoder_hidden = encoder_hidden[:decoder.n_layers]\n","        # Инициализируйте вход декодера с помощью SOS_token\n","        decoder_input = torch.ones(1, 1, device=device, dtype=torch.long) * SOS_token\n","        # Инициализируйте тензоры для добавления декодированных слов в\n","        all_tokens = torch.zeros([0], device=device, dtype=torch.long)\n","        all_scores = torch.zeros([0], device=device)\n","        # Итеративно декодируйте один токен слова за раз\n","        for _ in range(max_length):\n","            # Forward pass through decoder\n","            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden, encoder_outputs)\n","            # Получите наиболее вероятный токен слова и его оценку softmax.\n","            decoder_scores, decoder_input = torch.max(decoder_output, dim=1)\n","            # Запишите token and score\n","            all_tokens = torch.cat((all_tokens, decoder_input), dim=0)\n","            all_scores = torch.cat((all_scores, decoder_scores), dim=0)\n","            # Подготовьте текущий токен для\n","            # следующего ввода декодера (добавьте измерение)\n","            decoder_input = torch.unsqueeze(decoder_input, 0)\n","        # Возвратить коллекцию word tokens and scores\n","        return all_tokens, all_scores"]},{"cell_type":"markdown","metadata":{"id":"ylJGPm3_9eFA"},"source":["Оценка текста\n","================\n","\n","Теперь, когда у нас определен метод декодирования, мы можем написать функции для оценки предложения входной строки. Функция  `evaluate` управляет низкоуровневым процессом обработки предложения входной строки. Сначала мы форматируем предложение как входную партию индексов слов *batch\\_size==1*. Мы делаем это, преобразуя слова предложения в соответствующие им индексы и транспонируя измерения, чтобы подготовить тензор для наших моделей. Мы также создаем тензор, `lengths` tкоторый содержит длину нашего входного предложения. В этом случае `lengths` является скалярным, поскольку мы оцениваем только одно предложение за раз (batch\\_size==1). Затем мы получаем тензор декодированного предложения ответа, используя наш `GreedySearchDecoder`\n","объект  (`searcher`). Наконец, мы преобразуем индексы ответа в слова и возвращаем список декодированных слов.\n","\n","`evaluateInput` действует как пользовательский интерфейс для нашего чат-бота. При вызове появляется поле ввода текста, в котором мы можем ввести наше предложение запроса. После ввода нашего предложения ввода и нажатия *Enter*, наш текст нормализуется так же, как наши обучающие данные, и в конечном итоге подается в `evaluate` function to obtain a decoded output sentence. функцию для получения декодированного выходного предложения. Мы зацикливаем этот процесс, поэтому мы можем продолжать общаться с нашим ботом, пока не введем либо\n","\"q\" либо \"quit\".\n","\n","Наконец, если введенное предложение содержит слово, которого нет в словаре, мы корректно справляемся с этой проблемой, выводя сообщение об ошибке и предлагая пользователю ввести другое предложение.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B77R5BCO9eFA"},"outputs":[],"source":["def evaluate(encoder, decoder, searcher, voc, sentence, max_length=MAX_LENGTH):\n","    ### Форматировать входное предложение как пакет\n","    # words -> indexes\n","    indexes_batch = [indexesFromSentence(voc, sentence)]\n","    # Создать тензор длин\n","    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n","    # Транспонируйте размеры партии в соответствии с ожиданиями моделей.\n","    input_batch = torch.LongTensor(indexes_batch).transpose(0, 1)\n","    # Используйте подходящее устройство\n","    input_batch = input_batch.to(device)\n","    lengths = lengths.to(\"cpu\")\n","    # Расшифровать предложение с помощью поисковика\n","    tokens, scores = searcher(input_batch, lengths, max_length)\n","    # indexes -> words\n","    decoded_words = [voc.index2word[token.item()] for token in tokens]\n","    return decoded_words\n","\n","\n","def evaluateInput(encoder, decoder, searcher, voc):\n","    input_sentence = ''\n","    while(1):\n","        try:\n","            # Получить входное предложение\n","            input_sentence = input('> ')\n","            # Проверьте, завершен ли этот случай\n","            if input_sentence == 'q' or input_sentence == 'quit': break\n","            # Нормализовать предложение\n","            input_sentence = normalizeString(input_sentence)\n","            # Оценить предложение\n","            output_words = evaluate(encoder, decoder, searcher, voc, input_sentence)\n","            # Отформатируйте и распечатайте ответное предложение\n","            output_words[:] = [x for x in output_words if not (x == 'EOS' or x == 'PAD')]\n","            print('Bot:', ' '.join(output_words))\n","\n","        except KeyError:\n","            print(\"Error: Encountered unknown word.\")"]},{"cell_type":"markdown","metadata":{"id":"lluQ1_lK9eFA"},"source":["Запуск Модели\n","=========\n","\n","Наконец, пришло время запустить нашу модель!\n","\n","Независимо от того, хотим ли мы обучить или протестировать модель чат-бота, мы должны инициализировать отдельные модели кодера и декодера. В следующем блоке мы задаем желаемые конфигурации, выбираем начать с нуля или задать контрольную точку для загрузки, а также создаем и инициализируем модели. Не стесняйтесь играть с различными конфигурациями моделей для оптимизации производительности.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ABGdNOEm9eFB"},"outputs":[],"source":["# Настройка моделей\n","model_name = 'cb_model'\n","attn_model = 'dot'\n","#``attn_model = 'general'``\n","#``attn_model = 'concat'``\n","hidden_size = 500\n","encoder_n_layers = 2\n","decoder_n_layers = 2\n","dropout = 0.1\n","batch_size = 64\n","\n","# Set checkpoint to load from; set to None if starting from scratch\n","# Установите контрольную точку для загрузки;\n","# установите значение None, если начинаете с нуля\n","loadFilename = None\n","checkpoint_iter = 4000"]},{"cell_type":"markdown","metadata":{"id":"7z1SnNID9eFB"},"source":["Пример кода для загрузки из контрольной точки:\n","\n","``` {.sourceCode .python}\n","loadFilename = os.path.join(save_dir, model_name, corpus_name,\n","                    '{}-{}_{}'.format(encoder_n_layers, decoder_n_layers, hidden_size),\n","                    '{}_checkpoint.tar'.format(checkpoint_iter))\n","```\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EnI2vrAT9eFF"},"outputs":[],"source":["# Загрузить модель, если указано ``loadFilename``.\n","if loadFilename:\n","    # Если загружается на ту же машину, на которой обучалась модель\n","    checkpoint = torch.load(loadFilename)\n","    # При загрузке модели, обученной на GPU в CPU\n","    #checkpoint = torch.load(loadFilename, map_location=torch.device('cpu'))\n","    encoder_sd = checkpoint['en']\n","    decoder_sd = checkpoint['de']\n","    encoder_optimizer_sd = checkpoint['en_opt']\n","    decoder_optimizer_sd = checkpoint['de_opt']\n","    embedding_sd = checkpoint['embedding']\n","    voc.__dict__ = checkpoint['voc_dict']\n","\n","\n","print('Building encoder and decoder ...')\n","# Инициализация embbeding слов\n","embedding = nn.Embedding(voc.num_words, hidden_size)\n","if loadFilename:\n","    embedding.load_state_dict(embedding_sd)\n","# Инициализация encoder & decoder models\n","encoder = EncoderRNN(hidden_size, embedding, encoder_n_layers, dropout)\n","decoder = LuongAttnDecoderRNN(attn_model, embedding, hidden_size, voc.num_words, decoder_n_layers, dropout)\n","if loadFilename:\n","    encoder.load_state_dict(encoder_sd)\n","    decoder.load_state_dict(decoder_sd)\n","# Используйте подходящее устройство\n","encoder = encoder.to(device)\n","decoder = decoder.to(device)\n","print('Models built and ready to go!')"]},{"cell_type":"markdown","metadata":{"id":"ju-5eGsO9eFF"},"source":["Запуск обучения модели (Training)\n","============\n","\n","Если вы хотите обучить модель, выполните следующий блок.\n","\n","Сначала мы задаем параметры обучения, затем инициализируем наши оптимизаторы и, наконец, вызываем `trainIters` функцию для запуска наших итераций обучения.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p8Q-oZ449eFF"},"outputs":[],"source":["# Настройка обучения/оптимизации\n","clip = 50.0\n","teacher_forcing_ratio = 1.0\n","learning_rate = 0.0001\n","decoder_learning_ratio = 5.0\n","n_iteration = 4000\n","print_every = 1\n","save_every = 500\n","\n","# Ensure dropout layers are in train mode\n","# Убедитесь, что выпадающие слои находятся в режиме обучения.\n","encoder.train()\n","decoder.train()\n","\n","# Инициализировать оптимизаторы\n","print('Building optimizers ...')\n","encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n","decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate * decoder_learning_ratio)\n","if loadFilename:\n","    encoder_optimizer.load_state_dict(encoder_optimizer_sd)\n","    decoder_optimizer.load_state_dict(decoder_optimizer_sd)\n","\n","# Если у вас есть CUDA, настройте CUDA для вызова\n","for state in encoder_optimizer.state.values():\n","    for k, v in state.items():\n","        if isinstance(v, torch.Tensor):\n","            state[k] = v.cuda()\n","\n","for state in decoder_optimizer.state.values():\n","    for k, v in state.items():\n","        if isinstance(v, torch.Tensor):\n","            state[k] = v.cuda()\n","\n","# Запуск обучающих итераций\n","print(\"Starting Training!\")\n","trainIters(model_name, voc, pairs, encoder, decoder, encoder_optimizer, decoder_optimizer,\n","           embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size,\n","           print_every, save_every, clip, corpus_name, loadFilename)"]},{"cell_type":"markdown","metadata":{"id":"bkcQ-crd9eFF"},"source":["Выполнить оценку модели\n","==============\n","\n","Чтобы пообщаться с вашей моделью, запустите следующий блок.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iFQzcWiz9eFG"},"outputs":[],"source":["# Set dropout layers to ``eval`` mode\n","# Установите выпадающие слои в режим ``eval``.\n","encoder.eval()\n","decoder.eval()\n","\n","# Инициализировать модуль поиска\n","searcher = GreedySearchDecoder(encoder, decoder)\n","\n","# Начните общение (для начала раскомментируйте и введите следующую строку)\n","# evaluateInput(encoder, decoder, searcher, voc)"]},{"cell_type":"markdown","metadata":{"id":"TffRGO6M9eFG"},"source":["Заключение\n","==========\n","\n","На этом все, ребята. Поздравляю, теперь вы знаете основы построения генеративной модели чат-бота! Если вам интересно, вы можете попробовать настроить поведение чат-бота, настроив модель и параметры обучения, а также настроив данные, на которых вы обучаете модель.\n","\n","Ознакомьтесь с другими руководствами, чтобы узнать больше о крутых приложениях глубокого обучения в PyTorch!\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"},"colab":{"provenance":[{"file_id":"https://github.com/pytorch/tutorials/blob/gh-pages/_downloads/44a84f8c1764dbf61662d306ff9ed43a/chatbot_tutorial.ipynb","timestamp":1723808601872}]}},"nbformat":4,"nbformat_minor":0}